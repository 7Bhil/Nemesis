import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from pathlib import Path

class RAGMemory:
    """Gestionnaire de m√©moire vectorielle (RAG) avec FAISS et SentenceTransformers"""
    
    def __init__(self, storage_dir=".nemesis_memory"):
        self.storage_dir = Path(storage_dir)
        self.index_file = self.storage_dir / "vector.index"
        self.metadata_file = self.storage_dir / "metadata.json"
        
        # Cr√©ation du dossier de stockage si n√©cessaire
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        
        # Chargement du mod√®le d'embedding (l√©ger et multilingue)
        print("üì• Chargement du mod√®le d'embedding (peut prendre un moment)...")
        self.embedding_dim = 384
        self.model = None
        
        try:
            # 1. Tentative hors-ligne (rapide et s√ªr si d√©j√† t√©l√©charg√©)
            self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', local_files_only=True)
            # print("‚úÖ Mod√®le RAG charg√© (cache local).")
        except Exception:
            # 2. Tentative en ligne (si pas dans le cache)
            try:
                print("‚ö†Ô∏è Mod√®le non trouv√© localement, tentative de t√©l√©chargement...")
                self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            except Exception as e:
                print(f"‚ùå ERREUR CRITIQUE RAG: Impossible de charger le mod√®le d'embedding.")
                print(f"   D√©tail: {e}")
                print("   üí° Le syst√®me RAG sera d√©sactiv√© pour cette session.")
                self.model = None
        
        # Chargement ou cr√©ation de l'index FAISS
        self.index = None
        self.metadata = []
        self.load()

    def load(self):
        """Charge l'index et les m√©tadonn√©es depuis le disque"""
        if self.index_file.exists() and self.metadata_file.exists():
            try:
                self.index = faiss.read_index(str(self.index_file))
                with open(self.metadata_file, "r", encoding="utf-8") as f:
                    self.metadata = json.load(f)
                print(f"‚úÖ RAG: {len(self.metadata)} documents charg√©s.")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur chargement RAG: {e}")
                self._create_new_index()
        else:
            self._create_new_index()

    def _create_new_index(self):
        """Cr√©e un nouvel index vide"""
        self.index = faiss.IndexFlatL2(self.embedding_dim)
        self.metadata = []
        print("üÜï RAG: Nouvel index cr√©√©.")

    def save(self):
        """Sauvegarde l'index et les m√©tadonn√©es sur le disque"""
        if self.index:
            faiss.write_index(self.index, str(self.index_file))
            with open(self.metadata_file, "w", encoding="utf-8") as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
            # print("üíæ RAG: Index sauvegard√©.")

    def add_text(self, text, source="unknown", type="text"):
        """Ajoute un texte √† la m√©moire vectorielle"""
        if not text.strip():
            return
            
        # D√©coupage basique en chunks (par paragraphes ou taille fixe si tr√®s long)
        # Ici on fait simple: on coupe par paragraphes
        chunks = [c.strip() for c in text.split("\n\n") if c.strip()]
        
        if not chunks:
            return

        if not self.model:
             print("‚ö†Ô∏è RAG d√©sactiv√© (mod√®le non charg√©).")
             return

        embeddings = self.model.encode(chunks)
        self.index.add(np.array(embeddings).astype("float32"))
        
        for chunk in chunks:
            self.metadata.append({
                "content": chunk,
                "source": source,
                "type": type,
                "timestamp": self._get_timestamp()
            })
            
        self.save()
        print(f"‚ûï RAG: {len(chunks)} chunks ajout√©s depuis {source}.")

    def search(self, query, k=3):
        """Recherche les passages les plus pertinents pour une requ√™te"""
        if self.index.ntotal == 0:
            return []
            
        if not self.model:
            return []

        query_vector = self.model.encode([query])
        distances, indices = self.index.search(np.array(query_vector).astype("float32"), k)
        
        results = []
        for i, idx in enumerate(indices[0]):
            if idx != -1 and idx < len(self.metadata):
                item = self.metadata[idx]
                results.append({
                    "content": item["content"],
                    "source": item["source"],
                    "score": float(distances[0][i])
                })
        
        return results

    def _get_timestamp(self):
        from datetime import datetime
        return datetime.now().isoformat()
